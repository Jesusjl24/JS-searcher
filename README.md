# JS-searcher

ğŸ” **AI-Powered Job Search Application for SEEK**

An intelligent job search tool that scrapes SEEK.com.au and uses AI to match jobs with your resume, providing personalized recommendations.

---

## âœ¨ Features

- **Smart Job Scraping**: Automatically scrapes job listings from SEEK with advanced filtering
- **AI-Powered Matching**: Uses Mistral AI to analyze your resume and score job matches
- **Advanced Filters**: Filter by work type, location, salary, and posting date
- **Resume Analysis**: Extracts skills, experience, and qualifications from your resume (PDF, DOCX, TXT)
- **Match Insights**: Get detailed pros, cons, and strategic considerations for each job
- **Beautiful UI**: Clean Streamlit interface with job cards, metrics, and visualizations
- **Export Results**: Download job listings as CSV for further analysis

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- Chrome browser (for Selenium)
- Mistral API key ([Get one here](https://mistral.ai))

### Installation

1. **Clone the repository**
```bash
git clone <your-repo-url>
cd JS-searcher
```

2. **Create virtual environment** (recommended)
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables**

Create a `.env` file in the root directory:
```env
MISTRAL_API_KEY=your_mistral_api_key_here
```

5. **Run the application**
```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

---

## ğŸ“‹ Usage

### Basic Job Search

1. Enter job title (e.g., "Project Manager")
2. Enter location (e.g., "Sydney")
3. Click "Search Jobs"

### Advanced Search with Filters

Use the sidebar filters to refine your search:
- **Work Type**: Full time, Part time, Contract, Casual
- **Work Location**: On-site, Hybrid, Remote
- **Minimum Salary**: Select from predefined ranges
- **Date Posted**: Filter by recency

### AI-Powered Resume Matching

1. Upload your resume (PDF, DOCX, or TXT)
2. The AI will automatically analyze your:
   - Skills (technical and soft)
   - Years of experience
   - Education and certifications
   - Previous roles and industries
3. Search for jobs as normal
4. Each job will show:
   - Match score (0-100%)
   - Match recommendation (Strong/Good/Moderate/Weak)
   - Detailed analysis with pros, cons, and strategic advice

---

## ğŸ—ï¸ Project Structure

```
JS-searcher/
â”œâ”€â”€ .env                    # API keys (create this)
â”œâ”€â”€ .gitignore             # Git ignore file
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ app.py                # Main Streamlit application
â”œâ”€â”€ config.py             # Configuration constants
â”‚
â”œâ”€â”€ src/                  # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scraper.py        # SEEK job scraper
â”‚   â”œâ”€â”€ llm_scorer.py     # AI resume parser and job matcher
â”‚   â”œâ”€â”€ file_handlers.py  # Resume file processing
â”‚   â””â”€â”€ utils.py          # Utility functions
â”‚
â”œâ”€â”€ tests/                # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_scraper.py
â”‚   â”œâ”€â”€ test_llm_scorer.py
â”‚   â”œâ”€â”€ test_file_handlers.py
â”‚   â””â”€â”€ test_utils.py
â”‚
â””â”€â”€ data/                 # Data directory (auto-created)
    â””â”€â”€ jobs.csv          # Scraped jobs (auto-generated)
```

---

## ğŸ”§ Configuration

Edit `config.py` to customize:

### Scraping Settings
```python
SCRAPING_CONFIG = {
    "max_jobs_limit": 50,          # Maximum jobs per search
    "request_delay_min": 2,        # Minimum delay between requests
    "request_delay_max": 4,        # Maximum delay between requests
    "max_retries": 3,              # Retry attempts for failed requests
}
```

### LLM Settings
```python
LLM_CONFIG = {
    "model": "mistral-small-latest",
    "resume_max_chars": 5000,
    "job_description_max_chars": 2000,
    "temperature": 0.3,
}
```

### Resume Upload Settings
```python
RESUME_CONFIG = {
    "max_file_size_mb": 10,
    "allowed_extensions": ["pdf", "docx", "txt"],
}
```

---

## ğŸ›¡ï¸ Anti-Blocking Protection (NEW!)

The scraper now includes **professional-grade anti-blocking** features to protect you from IP bans and rate limiting - all **100% FREE**!

### Features Enabled by Default

âœ… **User Agent Rotation** - Randomly rotate between 12+ real browser user agents
âœ… **Request Header Randomization** - Mimic real browser headers
âœ… **Intelligent Rate Limiting** - Smart delays with jitter and human-like patterns
âœ… **Browser Fingerprint Randomization** - Random viewports and settings
âœ… **Session Rotation** - Automatically rotate sessions after N requests
âœ… **Exponential Backoff** - Smart retry logic for failed requests

### Why This is Better Than Free Proxies

**Free Proxies âŒ**
- Unreliable and slow
- Often malicious
- Short-lived
- Can be blocked faster than your IP

**Our Multi-Layer Strategy âœ…**
- Always available
- No performance impact
- More effective at avoiding blocks
- No security risks

### Configuration

Edit `config.py` to customize:

```python
ANTI_BLOCKING_CONFIG = {
    "enabled": True,  # Master switch
    "use_rate_limiting": True,  # Smart delays
    "use_header_rotation": True,  # Random headers
    "use_session_rotation": True,  # Session management
    "use_time_scheduling": False,  # Only scrape during business hours (optional)

    # Rate limiting (seconds)
    "rate_limit_base_delay": 2.0,  # Minimum delay
    "rate_limit_max_delay": 5.0,   # Maximum delay
    "rate_limit_jitter": True,      # Random variation
    "rate_limit_human_like": True,  # Occasional longer pauses

    # Session settings
    "session_lifetime_requests": 10,  # Rotate after N requests

    # Optional: Add proxies if you have them (not recommended for free proxies)
    "proxies": [],  # Format: ["http://ip:port"]
}
```

### How It Works

1. **User Agent Rotation**: Each request uses a different browser signature
2. **Smart Delays**: Variable delays between requests (2-5s base + human-like patterns)
3. **Human-Like Behavior**:
   - Every 5-10 requests: takes a longer break (5-15s)
   - 5% chance of extended break (30-60s)
   - Mimics someone reading job descriptions
4. **Session Management**: Creates new browser session every 10 requests
5. **Fingerprint Randomization**: Different viewport sizes and settings each time

### Performance Impact

- **Speed**: Slightly slower due to delays (by design!)
- **Success Rate**: Much higher (fewer blocks)
- **Recommendation**: Better to scrape 5 jobs safely than get blocked scraping 50

### Adding Proxies (Optional)

If you have access to **paid** proxy services, you can add them:

```python
# In config.py
ANTI_BLOCKING_CONFIG = {
    ...
    "proxies": [
        "http://proxy1.example.com:8080",
        "http://proxy2.example.com:8080",
    ]
}
```

**Note**: We don't recommend free proxy lists - they're usually slower and less reliable than using no proxy.

### Best Practices

1. **Keep max_jobs low** (5-10) even with anti-blocking
2. **Space out searches** - don't search every minute
3. **Use business hours** - enable `use_time_scheduling` to only scrape 9 AM-6 PM
4. **Be respectful** - SEEK provides a service, don't abuse it

---

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
pytest

# Run with verbose output
pytest -v

# Run specific test file
pytest tests/test_utils.py

# Run with coverage
pytest --cov=src tests/
```

### Manual Testing

Test individual modules:

```bash
# Test scraper
python src/scraper.py

# Test LLM scorer
python src/llm_scorer.py
```

---

## ğŸ“Š How It Works

### 1. Job Scraping

The scraper uses Selenium to:
1. Build a SEEK URL with your search criteria
2. Navigate to the search results page
3. Extract job cards using BeautifulSoup
4. Parse job details (title, company, location, salary, description)
5. Optionally fetch full descriptions from individual job pages
6. Save results to CSV

### 2. Resume Analysis

The AI resume parser:
1. Extracts text from your resume (supports PDF, DOCX, TXT)
2. Sends text to Mistral AI with structured prompting
3. Parses response to extract:
   - Technical and soft skills
   - Years of experience
   - Education and certifications
   - Previous job titles
   - Industries worked in
   - Career achievements

### 3. Job Matching

The AI job matcher:
1. Takes your resume profile and job details
2. Sends both to Mistral AI for comparison
3. Returns comprehensive analysis:
   - Overall match score (0-100)
   - Skill match percentage
   - Detailed reasoning
   - Pros and cons
   - Identified gaps
   - Strategic considerations

---

## âš™ï¸ Architecture

### Key Design Patterns

- **Modular Architecture**: Separation of concerns with dedicated modules
- **Context Managers**: Proper resource cleanup for Selenium drivers
- **Error Handling**: Custom exceptions and graceful degradation
- **Retry Logic**: Automatic retries with exponential backoff
- **Smart Truncation**: Sentence-boundary-aware text truncation
- **Input Validation**: Sanitization and validation of all user inputs

### Performance Optimizations

- **Caching**: Session state caching for job scores
- **Rate Limiting**: Configurable delays between requests
- **Lazy Loading**: Full descriptions fetched only when needed
- **Resource Pooling**: Context managers for driver lifecycle

---

## ğŸ›¡ï¸ Security Considerations

### Implemented Protections

âœ… **Input Sanitization**: All search terms and locations are sanitized
âœ… **File Validation**: Resume uploads validated for type and size
âœ… **API Key Protection**: Environment variables for sensitive data
âœ… **Rate Limiting**: Prevents overwhelming SEEK servers
âœ… **Error Handling**: Graceful failures without exposing internals

### Best Practices

- Never commit `.env` file (in `.gitignore`)
- Validate all user inputs before processing
- Use HTTPS for all API calls
- Limit file upload sizes
- Implement request rate limiting

---

## âš ï¸ Limitations & Considerations

### Rate Limiting
- Default: 5 jobs per search
- Recommendation: Keep searches small to avoid IP bans
- SEEK may block excessive requests

### AI Accuracy
- AI analysis is probabilistic, not guaranteed
- Review all job matches manually
- Results depend on resume quality and job description detail

### Browser Requirements
- Requires Chrome browser installed
- Headless mode enabled by default
- May require ChromeDriver updates

---

## ğŸ› Troubleshooting

### Common Issues

**"ChromeDriver not found"**
```bash
# The app auto-downloads ChromeDriver, but if it fails:
pip install --upgrade webdriver-manager
```

**"MISTRAL_API_KEY not found"**
```bash
# Create .env file with:
echo "MISTRAL_API_KEY=your_key_here" > .env
```

**"Module not found" errors**
```bash
# Reinstall dependencies:
pip install -r requirements.txt --force-reinstall
```

**Resume parsing fails**
```bash
# Check file format:
# - PDF: Must be text-based (not scanned images)
# - DOCX: Must be valid Word document
# - TXT: Must be UTF-8 encoded
```

**No jobs found**
```bash
# Try:
# 1. Broader search terms
# 2. Fewer filters
# 3. Different location
# 4. Wait a few minutes (possible rate limiting)
```

---

## ğŸ“ˆ Future Enhancements

### Planned Features
- [ ] Multi-page job scraping
- [ ] Job alert notifications
- [ ] Application tracking
- [ ] Resume optimization suggestions
- [ ] Cover letter generation
- [ ] Batch job scoring
- [ ] Database storage
- [ ] User authentication
- [ ] Mobile app

### Contributions Welcome!

See `CONTRIBUTING.md` for guidelines.

---

## ğŸ“ License

This project is for educational purposes. Please respect SEEK's terms of service and rate limits.

**Note**: Web scraping should be done responsibly:
- Use reasonable rate limits
- Don't overwhelm servers
- Respect robots.txt
- Check terms of service

---

## ğŸ™ Acknowledgments

- **SEEK**: For providing job listings
- **Mistral AI**: For LLM capabilities
- **Streamlit**: For the amazing UI framework
- **Selenium**: For web scraping capabilities

---

## ğŸ“ Support

For issues, questions, or contributions:
- Open an issue on GitHub
- Check existing documentation
- Review troubleshooting section

---

## ğŸ”„ Version History

### Version 2.0.0 (Current)
- âœ… Complete refactoring with modular architecture
- âœ… Improved error handling and logging
- âœ… Added comprehensive unit tests
- âœ… Enhanced AI prompts and parsing
- âœ… Better resource management
- âœ… Configuration-driven design
- âœ… Security improvements

### Version 1.0.0
- Basic SEEK scraping
- Simple resume matching
- Streamlit UI

---

**Happy Job Hunting! ğŸ¯**
